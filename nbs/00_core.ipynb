{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eventchain\n",
    "\n",
    "> Building and anylizing event chains in a convenient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EventChain:\n",
    "    \n",
    "    def __init__(self, df1: pd.DataFrame, df2: pd.DataFrame, user_col: str, timestamp_col: str, suffix):\n",
    "        \n",
    "        self.timestamp_a = f\"{timestamp_col}_{suffix[0]}\"\n",
    "        self.timestamp_b = f\"{timestamp_col}_{suffix[1]}\"\n",
    "\n",
    "        self.user_col = user_col    \n",
    "        self.any_event_A = df1.rename(columns={timestamp_col: self.timestamp_a})\n",
    "        self.any_event_B = df2.rename(columns={timestamp_col: self.timestamp_b})\n",
    "        self.first_event_A = self.any_event_A.groupby(self.user_col)[f\"{timestamp_col}_{suffix[0]}\"].min().reset_index()\n",
    "        self.last_event_A = self.any_event_A.groupby(self.user_col)[f\"{timestamp_col}_{suffix[0]}\"].max().reset_index()\n",
    "        self.first_event_B = self.any_event_B.groupby(self.user_col)[f\"{timestamp_col}_{suffix[1]}\"].min().reset_index()\n",
    "        self.last_event_B = self.any_event_B.groupby(self.user_col)[f\"{timestamp_col}_{suffix[1]}\"].max().reset_index()\n",
    "            \n",
    "    def anti_join(self, df1, df2): \n",
    "        return df1.merge(df2, how=\"left\", on=self.user_col, indicator=True).query(\"_merge == 'left_only'\").drop(columns=\"_merge\")\n",
    "\n",
    "    def before(self, df1, df2): \n",
    "        return (df1\n",
    "            .merge(df2, how=\"inner\", on=self.user_col).query(f\"{self.timestamp_a} < {self.timestamp_b}\")\n",
    "            .assign(gap=lambda x: x[self.timestamp_b] - x[self.timestamp_a]))\n",
    "\n",
    "    def before_or_equal(self, df1, df2): \n",
    "        return (df1\n",
    "            .merge(df2, how=\"inner\", on=self.user_col).query(f\"{self.timestamp_a} <= {self.timestamp_b}\")\n",
    "            .assign(gap=lambda x: x[self.timestamp_b] - x[self.timestamp_a]))\n",
    "\n",
    "    @property\n",
    "    def first_before_first(self): \n",
    "        return self.before(self.first_event_A, self.first_event_B)\n",
    "\n",
    "    @property\n",
    "    def first_before_or_equal_first(self):\n",
    "        return self.before_or_equal(self.first_event_A, self.first_event_B)\n",
    "    \n",
    "    @property\n",
    "    def first_before_last(self): \n",
    "        return self.before(self.first_event_A, self.last_event_B)\n",
    "\n",
    "    @property\n",
    "    def first_before_or_equal_last(self): \n",
    "        return self.before_or_equal(self.first_event_A, self.last_event_B)\n",
    "    \n",
    "    @property\n",
    "    def last_before_first(self):\n",
    "        return self.before(self.last_event_A, self.first_event_B)\n",
    "\n",
    "    @property\n",
    "    def last_before_or_equal_first(self):\n",
    "        return self.before_or_equal(self.last_event_A, self.first_event_B)\n",
    "\n",
    "    @property\n",
    "    def last_before_last(self):\n",
    "        return self.before(self.last_event_A, self.last_event_B)\n",
    "\n",
    "    @property\n",
    "    def last_before_or_equal_last(self):\n",
    "        return self.before_or_equal(self.last_event_A, self.last_event_B)\n",
    "\n",
    "    @property\n",
    "    def any_before_any(self):\n",
    "        return self.before_or_equal(self.any_event_A, self.any_event_B)\n",
    "\n",
    "    @property\n",
    "    def any_before_first(self):\n",
    "        return self.before_or_equal(self.any_event_A, self.first_event_B)\n",
    "\n",
    "    @property\n",
    "    def any_before_or_equal_first(self):\n",
    "        return self.before_or_equal(self.any_event_A, self.first_event_B)\n",
    "\n",
    "    @property\n",
    "    def any_before_last(self):\n",
    "        return self.before_or_equal(self.any_event_A, self.last_event_B)\n",
    "\n",
    "    @property\n",
    "    def any_before_or_equal_last(self):\n",
    "        return self.before_or_equal(self.any_event_A, self.last_event_B)\n",
    "\n",
    "    @property\n",
    "    def first_before_none(self): \n",
    "        return self.anti_join(self.first_event_A, self.any_event_B)\n",
    "    \n",
    "    @property\n",
    "    def last_before_none(self): \n",
    "        return self.anti_join(self.last_event_A, self.any_event_B)\n",
    "    \n",
    "    @property\n",
    "    def none_before_first(self): \n",
    "        return self.anti_join(self.first_event_B, self.any_event_A)\n",
    "    \n",
    "    @property\n",
    "    def none_before_last(self): \n",
    "        return self.anti_join(self.last_event_B, self.any_event_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_stats(nominator_df, denominator_df, user_col, gap_column='gap'):\n",
    "    nominator_df[gap_column] = nominator_df[gap_column].dt.days\n",
    "    nominator = nominator_df[user_col].nunique()\n",
    "    denominator = denominator_df[user_col].nunique()\n",
    "    n = len(nominator_df)\n",
    "    \n",
    "    summary_stats = {}\n",
    "    summary_stats['no_events_of_interest'] = nominator\n",
    "    summary_stats['all_events'] = denominator\n",
    "    summary_stats['pct'] = (nominator / denominator) * 100\n",
    "    summary_stats['mean_gap'] = nominator_df[gap_column].mean()\n",
    "    summary_stats['median_gap'] = nominator_df[gap_column].median()\n",
    "    summary_stats['std_dev'] = nominator_df[gap_column].std()\n",
    "    summary_stats['min_gap'] = nominator_df[gap_column].min()\n",
    "    summary_stats['max_gap'] = nominator_df[gap_column].max()\n",
    "    summary_stats['25th_percentile'] = nominator_df[gap_column].quantile(0.25)\n",
    "    summary_stats['50th_percentile'] = nominator_df[gap_column].quantile(0.5)\n",
    "    summary_stats['75th_percentile'] = nominator_df[gap_column].quantile(0.75)\n",
    "    summary_stats['skewness'] = nominator_df[gap_column].skew()\n",
    "    summary_stats['kurtosis'] = nominator_df[gap_column].kurt()\n",
    "    \n",
    "    confidence_level = 0.95\n",
    "    z_critical = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_critical * (summary_stats['std_dev'] / (n ** 0.5))\n",
    "    summary_stats['conf_interval_lower'] = summary_stats['mean_gap'] - margin_of_error\n",
    "    summary_stats['conf_interval_upper'] = summary_stats['mean_gap'] + margin_of_error\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"{:<30} {:<10}\".format('Metric', 'Value'))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    for key, value in summary_stats.items():\n",
    "        print(\"{:<30} {:<10}\".format(key, value))\n",
    "\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "shoppingcard = pd.read_csv('../data/visited.csv')\n",
    "purchased = pd.read_csv('../data/purchased.csv')\n",
    "\n",
    "shoppingcard['date'] = pd.to_datetime(shoppingcard['date'])\n",
    "purchased['date'] = pd.to_datetime(purchased['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "chain = EventChain(df1=shoppingcard, df2=purchased, user_col=\"user_id\", timestamp_col=\"date\", suffix=[\"added_to_shoppingcard\", \"purchased\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Metric                         Value     \n",
      "==================================================\n",
      "no_events_of_interest          4         \n",
      "all_events                     7         \n",
      "pct                            57.14285714285714\n",
      "mean_gap                       1.5       \n",
      "median_gap                     1.0       \n",
      "std_dev                        1.0       \n",
      "min_gap                        1         \n",
      "max_gap                        3         \n",
      "25th_percentile                1.0       \n",
      "50th_percentile                1.0       \n",
      "75th_percentile                1.5       \n",
      "skewness                       1.9999999999999998\n",
      "kurtosis                       4.0       \n",
      "conf_interval_lower            0.520018007729973\n",
      "conf_interval_upper            2.479981992270027\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "stats = get_stats(chain.first_before_first, chain.any_event_A, user_col=\"user_id\", gap_column=\"gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
